{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done!\n"
     ]
    }
   ],
   "source": [
    "from __future__ import print_function\n",
    "from keras.datasets import cifar10\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras.utils import np_utils\n",
    "from keras.callbacks import ReduceLROnPlateau, CSVLogger, EarlyStopping,ModelCheckpoint,ReduceLROnPlateau\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import resnet\n",
    "import os\n",
    "from tqdm import tqdm_notebook\n",
    "from keras.preprocessing.image import load_img\n",
    "from keras.models import load_model,Model\n",
    "from keras.layers import (\n",
    "    Conv2D,\n",
    "    Input,\n",
    "    Activation,\n",
    "    Dense,\n",
    "    Flatten,BatchNormalization,Add,MaxPooling2D,Dropout,AveragePooling2D\n",
    ")\n",
    "from keras import backend as K\n",
    "import gc\n",
    "print(\"Done!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_df=pd.read_csv(os.getcwd()+'/train.csv')\n",
    "test_df=pd.read_csv(os.getcwd()+'/val.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cd1ea71dc44b44bda4111fda2073cc50",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "A Jupyter Widget"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "train_df[\"data\"] = [np.array(load_img(os.getcwd()+\"/train/{}\".format(idx), target_size=(122,122))) / 255 for idx in tqdm_notebook(train_df['images'])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(122, 122, 3)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df['data'][0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "01fdaadd0cc34890a481f4d9b54bc1ed",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "A Jupyter Widget"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "test_df[\"data\"] = [np.array(load_img(os.getcwd()+\"/train/{}\".format(idx), target_size=(122,122))) / 255 for idx in tqdm_notebook(test_df['images'])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "lr_reducer = ReduceLROnPlateau(factor=np.sqrt(0.1), cooldown=0, patience=5, min_lr=0.1e-6)\n",
    "early_stopper = EarlyStopping(min_delta=0.001, patience=20)\n",
    "\n",
    "batch_size = 32\n",
    "nb_classes = 2\n",
    "nb_epoch = 200\n",
    "data_augmentation = False\n",
    "csv_logger = CSVLogger('resnet18_cat_dog.csv')\n",
    "img_rows, img_cols = 122, 122\n",
    "img_channels = 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "y_train=np_utils.to_categorical(train_df['label'], nb_classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "y_test=np_utils.to_categorical(test_df['label'], nb_classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X_train = np.array(train_df['data'].tolist())\n",
    "X_test = np.array(test_df['data'].tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def BatchActivate(x):\n",
    "    x = BatchNormalization()(x)\n",
    "    x = Activation('relu')(x)\n",
    "    return x\n",
    "\n",
    "def convolution_block(x, filters, size, strides=(1,1), padding='same', activation=True):\n",
    "    x = Conv2D(filters, size, strides=strides, padding=padding)(x)\n",
    "    if activation == True:\n",
    "        x = BatchActivate(x)\n",
    "    return x\n",
    "\n",
    "def residual_block(blockInput, num_filters=16, batch_activate = False):\n",
    "    x = BatchActivate(blockInput)\n",
    "    x = convolution_block(x, num_filters, (3,3) )\n",
    "    x = convolution_block(x, num_filters, (3,3), activation=False)\n",
    "    x = Add()([x, blockInput])\n",
    "    if batch_activate:\n",
    "        x = BatchActivate(x)\n",
    "    return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/wenjie/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:68: UserWarning: Update your `Model` call to the Keras 2 API: `Model(inputs=Tensor(\"in..., outputs=Tensor(\"de...)`\n"
     ]
    }
   ],
   "source": [
    "#model = resnet.ResnetBuilder.build_resnet_50((img_channels, img_rows, img_cols), nb_classes)\n",
    "\n",
    "input_layer=Input((122,122,3))\n",
    "\n",
    "conv1 = Conv2D(64, (7,7), strides=(2,2) ,activation='relu', padding=\"same\")(input_layer)\n",
    "p0 = MaxPooling2D(pool_size=(2, 2), strides=(2, 2))(conv1)\n",
    "\n",
    "conv1 = Conv2D(64, (3, 3), activation='relu', padding=\"same\")(p0)\n",
    "conv1 = Conv2D(64, (3, 3), activation=None, padding=\"same\")(conv1)\n",
    "conv1 = residual_block(conv1,64)\n",
    "conv1 = residual_block(conv1,64,True)\n",
    "pool1 = Dropout(0.1)(conv1)\n",
    "\n",
    "conv1 = Conv2D(64, (3, 3), activation='relu', padding=\"same\")(pool1)\n",
    "conv1 = Conv2D(64, (3, 3), activation=None, padding=\"same\")(conv1)\n",
    "conv1 = residual_block(conv1,64)\n",
    "conv1 = residual_block(conv1,64,True)\n",
    "pool1 = Dropout(0.1)(conv1)\n",
    "\n",
    "conv2 = Conv2D(64, (3, 3), activation='relu', padding=\"same\")(pool1)\n",
    "conv2 = Conv2D(128, (3, 3), activation=None, padding=\"same\")(conv2)\n",
    "conv2 = residual_block(conv2,128)\n",
    "conv2 = residual_block(conv2,128)\n",
    "pool2 = Dropout(0.1)(conv2)\n",
    "pool2 = MaxPooling2D()(pool2)\n",
    "\n",
    "conv2 = Conv2D(64, (3, 3), activation='relu', padding=\"same\")(pool2)\n",
    "conv2 = Conv2D(128, (3, 3), activation=None, padding=\"same\")(pool2)\n",
    "conv2 = residual_block(conv2,128)\n",
    "conv2 = residual_block(conv2,128,True)\n",
    "pool2 = Dropout(0.1)(conv2)\n",
    "\n",
    "conv3 = Conv2D(64, (3, 3), activation='relu', padding=\"same\")(pool2)\n",
    "conv3 = Conv2D(256, (3, 3), activation=None, padding=\"same\")(conv3)\n",
    "conv3 = residual_block(conv3,256)\n",
    "conv3 = residual_block(conv3,256,True)\n",
    "pool3 = Dropout(0.1)(conv3)\n",
    "\n",
    "conv3 = Conv2D(256, (3, 3), activation='relu', padding=\"same\")(pool3)\n",
    "conv3 = Conv2D(256, (3, 3), activation=None, padding=\"same\")(conv3)\n",
    "conv3 = residual_block(conv3,256)\n",
    "conv3 = residual_block(conv3,256,True)\n",
    "pool3 = Dropout(0.1)(conv3)\n",
    "\n",
    "conv3 = Conv2D(256, (3, 3), activation='relu', padding=\"same\")(pool3)\n",
    "conv3 = Conv2D(512, (3, 3), activation=None, padding=\"same\")(conv3)\n",
    "conv3 = residual_block(conv3,512)\n",
    "conv3 = residual_block(conv3,512,True)\n",
    "conv3 = Conv2D(256, (3, 3), activation='relu', padding=\"same\")(conv3)\n",
    "\n",
    "if K.image_dim_ordering() == 'tf':\n",
    "    ROW_AXIS = 1\n",
    "    COL_AXIS = 2\n",
    "    CHANNEL_AXIS = 3\n",
    "else:\n",
    "    CHANNEL_AXIS = 1\n",
    "    ROW_AXIS = 2\n",
    "    COL_AXIS = 3\n",
    "\n",
    "block_shape = K.int_shape(conv3)\n",
    "pool4 = AveragePooling2D(pool_size=(block_shape[ROW_AXIS], block_shape[COL_AXIS]),\n",
    "                         strides=(1, 1))(conv3)\n",
    "\n",
    "\n",
    "fla = Flatten()(pool4)\n",
    "dense = Dense(units=2, kernel_initializer=\"he_normal\",\n",
    "                      activation=\"softmax\")(fla)\n",
    "model=Model(inputs=input_layer,output=dense)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model.compile(loss='categorical_crossentropy',\n",
    "              optimizer='adam',\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_1 (InputLayer)            (None, 122, 122, 3)  0                                            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_1 (Conv2D)               (None, 61, 61, 64)   9472        input_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2D)  (None, 30, 30, 64)   0           conv2d_1[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_2 (Conv2D)               (None, 30, 30, 64)   36928       max_pooling2d_1[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_3 (Conv2D)               (None, 30, 30, 64)   36928       conv2d_2[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_1 (BatchNor (None, 30, 30, 64)   256         conv2d_3[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "activation_1 (Activation)       (None, 30, 30, 64)   0           batch_normalization_1[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_4 (Conv2D)               (None, 30, 30, 64)   36928       activation_1[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_2 (BatchNor (None, 30, 30, 64)   256         conv2d_4[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "activation_2 (Activation)       (None, 30, 30, 64)   0           batch_normalization_2[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_5 (Conv2D)               (None, 30, 30, 64)   36928       activation_2[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "add_1 (Add)                     (None, 30, 30, 64)   0           conv2d_5[0][0]                   \n",
      "                                                                 conv2d_3[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_3 (BatchNor (None, 30, 30, 64)   256         add_1[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "activation_3 (Activation)       (None, 30, 30, 64)   0           batch_normalization_3[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_6 (Conv2D)               (None, 30, 30, 64)   36928       activation_3[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_4 (BatchNor (None, 30, 30, 64)   256         conv2d_6[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "activation_4 (Activation)       (None, 30, 30, 64)   0           batch_normalization_4[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_7 (Conv2D)               (None, 30, 30, 64)   36928       activation_4[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "add_2 (Add)                     (None, 30, 30, 64)   0           conv2d_7[0][0]                   \n",
      "                                                                 add_1[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_5 (BatchNor (None, 30, 30, 64)   256         add_2[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "activation_5 (Activation)       (None, 30, 30, 64)   0           batch_normalization_5[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "dropout_1 (Dropout)             (None, 30, 30, 64)   0           activation_5[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_8 (Conv2D)               (None, 30, 30, 64)   36928       dropout_1[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_9 (Conv2D)               (None, 30, 30, 64)   36928       conv2d_8[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_6 (BatchNor (None, 30, 30, 64)   256         conv2d_9[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "activation_6 (Activation)       (None, 30, 30, 64)   0           batch_normalization_6[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_10 (Conv2D)              (None, 30, 30, 64)   36928       activation_6[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_7 (BatchNor (None, 30, 30, 64)   256         conv2d_10[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_7 (Activation)       (None, 30, 30, 64)   0           batch_normalization_7[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_11 (Conv2D)              (None, 30, 30, 64)   36928       activation_7[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "add_3 (Add)                     (None, 30, 30, 64)   0           conv2d_11[0][0]                  \n",
      "                                                                 conv2d_9[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_8 (BatchNor (None, 30, 30, 64)   256         add_3[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "activation_8 (Activation)       (None, 30, 30, 64)   0           batch_normalization_8[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_12 (Conv2D)              (None, 30, 30, 64)   36928       activation_8[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_9 (BatchNor (None, 30, 30, 64)   256         conv2d_12[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_9 (Activation)       (None, 30, 30, 64)   0           batch_normalization_9[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_13 (Conv2D)              (None, 30, 30, 64)   36928       activation_9[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "add_4 (Add)                     (None, 30, 30, 64)   0           conv2d_13[0][0]                  \n",
      "                                                                 add_3[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_10 (BatchNo (None, 30, 30, 64)   256         add_4[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "activation_10 (Activation)      (None, 30, 30, 64)   0           batch_normalization_10[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "dropout_2 (Dropout)             (None, 30, 30, 64)   0           activation_10[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_14 (Conv2D)              (None, 30, 30, 64)   36928       dropout_2[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_15 (Conv2D)              (None, 30, 30, 128)  73856       conv2d_14[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_11 (BatchNo (None, 30, 30, 128)  512         conv2d_15[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_11 (Activation)      (None, 30, 30, 128)  0           batch_normalization_11[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_16 (Conv2D)              (None, 30, 30, 128)  147584      activation_11[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_12 (BatchNo (None, 30, 30, 128)  512         conv2d_16[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_12 (Activation)      (None, 30, 30, 128)  0           batch_normalization_12[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_17 (Conv2D)              (None, 30, 30, 128)  147584      activation_12[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "add_5 (Add)                     (None, 30, 30, 128)  0           conv2d_17[0][0]                  \n",
      "                                                                 conv2d_15[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_13 (BatchNo (None, 30, 30, 128)  512         add_5[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "activation_13 (Activation)      (None, 30, 30, 128)  0           batch_normalization_13[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_18 (Conv2D)              (None, 30, 30, 128)  147584      activation_13[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_14 (BatchNo (None, 30, 30, 128)  512         conv2d_18[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_14 (Activation)      (None, 30, 30, 128)  0           batch_normalization_14[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_19 (Conv2D)              (None, 30, 30, 128)  147584      activation_14[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "add_6 (Add)                     (None, 30, 30, 128)  0           conv2d_19[0][0]                  \n",
      "                                                                 add_5[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "dropout_3 (Dropout)             (None, 30, 30, 128)  0           add_6[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_2 (MaxPooling2D)  (None, 15, 15, 128)  0           dropout_3[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_21 (Conv2D)              (None, 15, 15, 128)  147584      max_pooling2d_2[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_15 (BatchNo (None, 15, 15, 128)  512         conv2d_21[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_15 (Activation)      (None, 15, 15, 128)  0           batch_normalization_15[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_22 (Conv2D)              (None, 15, 15, 128)  147584      activation_15[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_16 (BatchNo (None, 15, 15, 128)  512         conv2d_22[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_16 (Activation)      (None, 15, 15, 128)  0           batch_normalization_16[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_23 (Conv2D)              (None, 15, 15, 128)  147584      activation_16[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "add_7 (Add)                     (None, 15, 15, 128)  0           conv2d_23[0][0]                  \n",
      "                                                                 conv2d_21[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_17 (BatchNo (None, 15, 15, 128)  512         add_7[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "activation_17 (Activation)      (None, 15, 15, 128)  0           batch_normalization_17[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_24 (Conv2D)              (None, 15, 15, 128)  147584      activation_17[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_18 (BatchNo (None, 15, 15, 128)  512         conv2d_24[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_18 (Activation)      (None, 15, 15, 128)  0           batch_normalization_18[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_25 (Conv2D)              (None, 15, 15, 128)  147584      activation_18[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "add_8 (Add)                     (None, 15, 15, 128)  0           conv2d_25[0][0]                  \n",
      "                                                                 add_7[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_19 (BatchNo (None, 15, 15, 128)  512         add_8[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "activation_19 (Activation)      (None, 15, 15, 128)  0           batch_normalization_19[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "dropout_4 (Dropout)             (None, 15, 15, 128)  0           activation_19[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_26 (Conv2D)              (None, 15, 15, 64)   73792       dropout_4[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_27 (Conv2D)              (None, 15, 15, 256)  147712      conv2d_26[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_20 (BatchNo (None, 15, 15, 256)  1024        conv2d_27[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_20 (Activation)      (None, 15, 15, 256)  0           batch_normalization_20[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_28 (Conv2D)              (None, 15, 15, 256)  590080      activation_20[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_21 (BatchNo (None, 15, 15, 256)  1024        conv2d_28[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_21 (Activation)      (None, 15, 15, 256)  0           batch_normalization_21[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_29 (Conv2D)              (None, 15, 15, 256)  590080      activation_21[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "add_9 (Add)                     (None, 15, 15, 256)  0           conv2d_29[0][0]                  \n",
      "                                                                 conv2d_27[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_22 (BatchNo (None, 15, 15, 256)  1024        add_9[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "activation_22 (Activation)      (None, 15, 15, 256)  0           batch_normalization_22[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_30 (Conv2D)              (None, 15, 15, 256)  590080      activation_22[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_23 (BatchNo (None, 15, 15, 256)  1024        conv2d_30[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_23 (Activation)      (None, 15, 15, 256)  0           batch_normalization_23[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_31 (Conv2D)              (None, 15, 15, 256)  590080      activation_23[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "add_10 (Add)                    (None, 15, 15, 256)  0           conv2d_31[0][0]                  \n",
      "                                                                 add_9[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_24 (BatchNo (None, 15, 15, 256)  1024        add_10[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "activation_24 (Activation)      (None, 15, 15, 256)  0           batch_normalization_24[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "dropout_5 (Dropout)             (None, 15, 15, 256)  0           activation_24[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_32 (Conv2D)              (None, 15, 15, 256)  590080      dropout_5[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_33 (Conv2D)              (None, 15, 15, 256)  590080      conv2d_32[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_25 (BatchNo (None, 15, 15, 256)  1024        conv2d_33[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_25 (Activation)      (None, 15, 15, 256)  0           batch_normalization_25[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_34 (Conv2D)              (None, 15, 15, 256)  590080      activation_25[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_26 (BatchNo (None, 15, 15, 256)  1024        conv2d_34[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_26 (Activation)      (None, 15, 15, 256)  0           batch_normalization_26[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_35 (Conv2D)              (None, 15, 15, 256)  590080      activation_26[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "add_11 (Add)                    (None, 15, 15, 256)  0           conv2d_35[0][0]                  \n",
      "                                                                 conv2d_33[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_27 (BatchNo (None, 15, 15, 256)  1024        add_11[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "activation_27 (Activation)      (None, 15, 15, 256)  0           batch_normalization_27[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_36 (Conv2D)              (None, 15, 15, 256)  590080      activation_27[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_28 (BatchNo (None, 15, 15, 256)  1024        conv2d_36[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_28 (Activation)      (None, 15, 15, 256)  0           batch_normalization_28[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_37 (Conv2D)              (None, 15, 15, 256)  590080      activation_28[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "add_12 (Add)                    (None, 15, 15, 256)  0           conv2d_37[0][0]                  \n",
      "                                                                 add_11[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_29 (BatchNo (None, 15, 15, 256)  1024        add_12[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "activation_29 (Activation)      (None, 15, 15, 256)  0           batch_normalization_29[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "dropout_6 (Dropout)             (None, 15, 15, 256)  0           activation_29[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_38 (Conv2D)              (None, 15, 15, 256)  590080      dropout_6[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_39 (Conv2D)              (None, 15, 15, 512)  1180160     conv2d_38[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_30 (BatchNo (None, 15, 15, 512)  2048        conv2d_39[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_30 (Activation)      (None, 15, 15, 512)  0           batch_normalization_30[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_40 (Conv2D)              (None, 15, 15, 512)  2359808     activation_30[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_31 (BatchNo (None, 15, 15, 512)  2048        conv2d_40[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_31 (Activation)      (None, 15, 15, 512)  0           batch_normalization_31[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_41 (Conv2D)              (None, 15, 15, 512)  2359808     activation_31[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "add_13 (Add)                    (None, 15, 15, 512)  0           conv2d_41[0][0]                  \n",
      "                                                                 conv2d_39[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_32 (BatchNo (None, 15, 15, 512)  2048        add_13[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "activation_32 (Activation)      (None, 15, 15, 512)  0           batch_normalization_32[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_42 (Conv2D)              (None, 15, 15, 512)  2359808     activation_32[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_33 (BatchNo (None, 15, 15, 512)  2048        conv2d_42[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_33 (Activation)      (None, 15, 15, 512)  0           batch_normalization_33[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_43 (Conv2D)              (None, 15, 15, 512)  2359808     activation_33[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "add_14 (Add)                    (None, 15, 15, 512)  0           conv2d_43[0][0]                  \n",
      "                                                                 add_13[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_34 (BatchNo (None, 15, 15, 512)  2048        add_14[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "activation_34 (Activation)      (None, 15, 15, 512)  0           batch_normalization_34[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_44 (Conv2D)              (None, 15, 15, 256)  1179904     activation_34[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "average_pooling2d_1 (AveragePoo (None, 1, 1, 256)    0           conv2d_44[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "flatten_1 (Flatten)             (None, 256)          0           average_pooling2d_1[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "dense_1 (Dense)                 (None, 2)            514         flatten_1[0][0]                  \n",
      "==================================================================================================\n",
      "Total params: 20,431,490\n",
      "Trainable params: 20,417,666\n",
      "Non-trainable params: 13,824\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 8000 samples, validate on 2000 samples\n",
      "Epoch 1/200\n",
      "8000/8000 [==============================] - 56s 7ms/step - loss: 0.7151 - acc: 0.4958 - val_loss: 0.6933 - val_acc: 0.4945\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 0.69327, saving model to ./Third_net.model\n",
      "Epoch 2/200\n",
      "8000/8000 [==============================] - 50s 6ms/step - loss: 0.6892 - acc: 0.5341 - val_loss: 5.4822 - val_acc: 0.5065\n",
      "\n",
      "Epoch 00002: val_loss did not improve from 0.69327\n",
      "Epoch 3/200\n",
      "8000/8000 [==============================] - 50s 6ms/step - loss: 0.6873 - acc: 0.5406 - val_loss: 0.6788 - val_acc: 0.5550\n",
      "\n",
      "Epoch 00003: val_loss improved from 0.69327 to 0.67876, saving model to ./Third_net.model\n",
      "Epoch 4/200\n",
      "8000/8000 [==============================] - 51s 6ms/step - loss: 0.6800 - acc: 0.5736 - val_loss: 0.6888 - val_acc: 0.5220\n",
      "\n",
      "Epoch 00004: val_loss did not improve from 0.67876\n",
      "Epoch 5/200\n",
      "8000/8000 [==============================] - 51s 6ms/step - loss: 0.6765 - acc: 0.5715 - val_loss: 3.2371 - val_acc: 0.5075\n",
      "\n",
      "Epoch 00005: val_loss did not improve from 0.67876\n",
      "Epoch 6/200\n",
      "8000/8000 [==============================] - 52s 6ms/step - loss: 0.6716 - acc: 0.5891 - val_loss: 0.8597 - val_acc: 0.5055\n",
      "\n",
      "Epoch 00006: val_loss did not improve from 0.67876\n",
      "Epoch 7/200\n",
      "8000/8000 [==============================] - 51s 6ms/step - loss: 0.6627 - acc: 0.6075 - val_loss: 0.6929 - val_acc: 0.5405\n",
      "\n",
      "Epoch 00007: val_loss did not improve from 0.67876\n",
      "Epoch 8/200\n",
      "8000/8000 [==============================] - 51s 6ms/step - loss: 0.6546 - acc: 0.6221 - val_loss: 1.4891 - val_acc: 0.5055\n",
      "\n",
      "Epoch 00008: val_loss did not improve from 0.67876\n",
      "Epoch 9/200\n",
      "8000/8000 [==============================] - 52s 6ms/step - loss: 0.6332 - acc: 0.6566 - val_loss: 0.7063 - val_acc: 0.5235\n",
      "\n",
      "Epoch 00009: val_loss did not improve from 0.67876\n",
      "Epoch 10/200\n",
      "8000/8000 [==============================] - 52s 6ms/step - loss: 0.6192 - acc: 0.6775 - val_loss: 0.7830 - val_acc: 0.5910\n",
      "\n",
      "Epoch 00010: val_loss did not improve from 0.67876\n",
      "Epoch 11/200\n",
      "8000/8000 [==============================] - 56s 7ms/step - loss: 0.6120 - acc: 0.6764 - val_loss: 0.6693 - val_acc: 0.5825\n",
      "\n",
      "Epoch 00011: val_loss improved from 0.67876 to 0.66932, saving model to ./Third_net.model\n",
      "Epoch 12/200\n",
      "8000/8000 [==============================] - 52s 6ms/step - loss: 0.5974 - acc: 0.6971 - val_loss: 1.3127 - val_acc: 0.5165\n",
      "\n",
      "Epoch 00012: val_loss did not improve from 0.66932\n",
      "Epoch 13/200\n",
      "8000/8000 [==============================] - 52s 6ms/step - loss: 0.5870 - acc: 0.7074 - val_loss: 0.8548 - val_acc: 0.5890\n",
      "\n",
      "Epoch 00013: val_loss did not improve from 0.66932\n",
      "Epoch 14/200\n",
      "8000/8000 [==============================] - 52s 6ms/step - loss: 0.5706 - acc: 0.7205 - val_loss: 0.6334 - val_acc: 0.6880\n",
      "\n",
      "Epoch 00014: val_loss improved from 0.66932 to 0.63336, saving model to ./Third_net.model\n",
      "Epoch 15/200\n",
      "8000/8000 [==============================] - 52s 6ms/step - loss: 0.5591 - acc: 0.7255 - val_loss: 0.6683 - val_acc: 0.6530\n",
      "\n",
      "Epoch 00015: val_loss did not improve from 0.63336\n",
      "Epoch 16/200\n",
      "8000/8000 [==============================] - 52s 6ms/step - loss: 0.5396 - acc: 0.7449 - val_loss: 1.0929 - val_acc: 0.5720\n",
      "\n",
      "Epoch 00016: val_loss did not improve from 0.63336\n",
      "Epoch 17/200\n",
      "8000/8000 [==============================] - 52s 7ms/step - loss: 0.5165 - acc: 0.7605 - val_loss: 0.5698 - val_acc: 0.7145\n",
      "\n",
      "Epoch 00017: val_loss improved from 0.63336 to 0.56978, saving model to ./Third_net.model\n",
      "Epoch 18/200\n",
      "8000/8000 [==============================] - 52s 6ms/step - loss: 0.4982 - acc: 0.7724 - val_loss: 0.7068 - val_acc: 0.5815\n",
      "\n",
      "Epoch 00018: val_loss did not improve from 0.56978\n",
      "Epoch 19/200\n",
      "8000/8000 [==============================] - 52s 6ms/step - loss: 0.4818 - acc: 0.7845 - val_loss: 0.6648 - val_acc: 0.6875\n",
      "\n",
      "Epoch 00019: val_loss did not improve from 0.56978\n",
      "Epoch 20/200\n",
      "8000/8000 [==============================] - 52s 6ms/step - loss: 0.4656 - acc: 0.7983 - val_loss: 0.7970 - val_acc: 0.6665\n",
      "\n",
      "Epoch 00020: val_loss did not improve from 0.56978\n",
      "Epoch 21/200\n",
      "8000/8000 [==============================] - 52s 6ms/step - loss: 0.4491 - acc: 0.8015 - val_loss: 1.1082 - val_acc: 0.6215\n",
      "\n",
      "Epoch 00021: val_loss did not improve from 0.56978\n",
      "Epoch 22/200\n",
      "8000/8000 [==============================] - 52s 6ms/step - loss: 0.4322 - acc: 0.8163 - val_loss: 0.4983 - val_acc: 0.7695\n",
      "\n",
      "Epoch 00022: val_loss improved from 0.56978 to 0.49828, saving model to ./Third_net.model\n",
      "Epoch 23/200\n",
      "8000/8000 [==============================] - 52s 6ms/step - loss: 0.4090 - acc: 0.8306 - val_loss: 0.4920 - val_acc: 0.7810\n",
      "\n",
      "Epoch 00023: val_loss improved from 0.49828 to 0.49202, saving model to ./Third_net.model\n",
      "Epoch 24/200\n",
      "8000/8000 [==============================] - 52s 6ms/step - loss: 0.3986 - acc: 0.8351 - val_loss: 0.7904 - val_acc: 0.5590\n",
      "\n",
      "Epoch 00024: val_loss did not improve from 0.49202\n",
      "Epoch 25/200\n",
      "8000/8000 [==============================] - 52s 6ms/step - loss: 0.3766 - acc: 0.8476 - val_loss: 0.8225 - val_acc: 0.6975\n",
      "\n",
      "Epoch 00025: val_loss did not improve from 0.49202\n",
      "Epoch 26/200\n",
      "8000/8000 [==============================] - 52s 6ms/step - loss: 0.3599 - acc: 0.8544 - val_loss: 0.8646 - val_acc: 0.5400\n",
      "\n",
      "Epoch 00026: val_loss did not improve from 0.49202\n",
      "Epoch 27/200\n",
      "8000/8000 [==============================] - 52s 6ms/step - loss: 0.3400 - acc: 0.8634 - val_loss: 0.4895 - val_acc: 0.8150\n",
      "\n",
      "Epoch 00027: val_loss improved from 0.49202 to 0.48949, saving model to ./Third_net.model\n",
      "Epoch 28/200\n",
      "8000/8000 [==============================] - 52s 6ms/step - loss: 0.3052 - acc: 0.8764 - val_loss: 0.9269 - val_acc: 0.7270\n",
      "\n",
      "Epoch 00028: val_loss did not improve from 0.48949\n",
      "Epoch 29/200\n",
      "8000/8000 [==============================] - 52s 6ms/step - loss: 0.2842 - acc: 0.8845 - val_loss: 0.9273 - val_acc: 0.6455\n",
      "\n",
      "Epoch 00029: val_loss did not improve from 0.48949\n",
      "Epoch 30/200\n",
      "8000/8000 [==============================] - 52s 6ms/step - loss: 0.2762 - acc: 0.8853 - val_loss: 0.4440 - val_acc: 0.8130\n",
      "\n",
      "Epoch 00030: val_loss improved from 0.48949 to 0.44395, saving model to ./Third_net.model\n",
      "Epoch 31/200\n",
      "8000/8000 [==============================] - 52s 6ms/step - loss: 0.2557 - acc: 0.8931 - val_loss: 2.2831 - val_acc: 0.5860\n",
      "\n",
      "Epoch 00031: val_loss did not improve from 0.44395\n",
      "Epoch 32/200\n",
      "8000/8000 [==============================] - 52s 6ms/step - loss: 0.2396 - acc: 0.9064 - val_loss: 0.6933 - val_acc: 0.7510\n",
      "\n",
      "Epoch 00032: val_loss did not improve from 0.44395\n",
      "Epoch 33/200\n",
      "8000/8000 [==============================] - 52s 6ms/step - loss: 0.2192 - acc: 0.9127 - val_loss: 0.5054 - val_acc: 0.7990\n",
      "\n",
      "Epoch 00033: val_loss did not improve from 0.44395\n",
      "Epoch 34/200\n",
      "8000/8000 [==============================] - 52s 6ms/step - loss: 0.2058 - acc: 0.9193 - val_loss: 0.5769 - val_acc: 0.7985\n",
      "\n",
      "Epoch 00034: val_loss did not improve from 0.44395\n",
      "Epoch 35/200\n",
      "8000/8000 [==============================] - 52s 6ms/step - loss: 0.1895 - acc: 0.9253 - val_loss: 0.7988 - val_acc: 0.7520\n",
      "\n",
      "Epoch 00035: val_loss did not improve from 0.44395\n",
      "Epoch 36/200\n",
      "8000/8000 [==============================] - 52s 6ms/step - loss: 0.1199 - acc: 0.9582 - val_loss: 0.5898 - val_acc: 0.7980\n",
      "\n",
      "Epoch 00036: val_loss did not improve from 0.44395\n",
      "Epoch 37/200\n",
      "8000/8000 [==============================] - 52s 6ms/step - loss: 0.0955 - acc: 0.9640 - val_loss: 0.4400 - val_acc: 0.8510\n",
      "\n",
      "Epoch 00037: val_loss improved from 0.44395 to 0.43999, saving model to ./Third_net.model\n",
      "Epoch 38/200\n",
      "8000/8000 [==============================] - 52s 6ms/step - loss: 0.0809 - acc: 0.9711 - val_loss: 0.5573 - val_acc: 0.8310\n",
      "\n",
      "Epoch 00038: val_loss did not improve from 0.43999\n",
      "Epoch 39/200\n",
      "8000/8000 [==============================] - 52s 6ms/step - loss: 0.0694 - acc: 0.9740 - val_loss: 0.5932 - val_acc: 0.8410\n",
      "\n",
      "Epoch 00039: val_loss did not improve from 0.43999\n",
      "Epoch 40/200\n",
      "8000/8000 [==============================] - 52s 6ms/step - loss: 0.0712 - acc: 0.9720 - val_loss: 0.5343 - val_acc: 0.8455\n",
      "\n",
      "Epoch 00040: val_loss did not improve from 0.43999\n",
      "Epoch 41/200\n",
      "8000/8000 [==============================] - 52s 6ms/step - loss: 0.0501 - acc: 0.9825 - val_loss: 0.5995 - val_acc: 0.8410\n",
      "\n",
      "Epoch 00041: val_loss did not improve from 0.43999\n",
      "Epoch 42/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8000/8000 [==============================] - 52s 6ms/step - loss: 0.0489 - acc: 0.9814 - val_loss: 0.7523 - val_acc: 0.8080\n",
      "\n",
      "Epoch 00042: val_loss did not improve from 0.43999\n",
      "Epoch 43/200\n",
      "8000/8000 [==============================] - 52s 6ms/step - loss: 0.0298 - acc: 0.9900 - val_loss: 0.6153 - val_acc: 0.8505\n",
      "\n",
      "Epoch 00043: val_loss did not improve from 0.43999\n",
      "Epoch 44/200\n",
      "8000/8000 [==============================] - 52s 6ms/step - loss: 0.0255 - acc: 0.9908 - val_loss: 0.6925 - val_acc: 0.8450\n",
      "\n",
      "Epoch 00044: val_loss did not improve from 0.43999\n",
      "Epoch 45/200\n",
      "8000/8000 [==============================] - 52s 6ms/step - loss: 0.0200 - acc: 0.9934 - val_loss: 0.6738 - val_acc: 0.8555\n",
      "\n",
      "Epoch 00045: val_loss did not improve from 0.43999\n",
      "Epoch 46/200\n",
      "8000/8000 [==============================] - 52s 6ms/step - loss: 0.0164 - acc: 0.9954 - val_loss: 0.7238 - val_acc: 0.8505\n",
      "\n",
      "Epoch 00046: val_loss did not improve from 0.43999\n",
      "Epoch 47/200\n",
      "8000/8000 [==============================] - 52s 6ms/step - loss: 0.0223 - acc: 0.9919 - val_loss: 0.7607 - val_acc: 0.8425\n",
      "\n",
      "Epoch 00047: val_loss did not improve from 0.43999\n",
      "Epoch 48/200\n",
      "8000/8000 [==============================] - 52s 6ms/step - loss: 0.0219 - acc: 0.9929 - val_loss: 0.6896 - val_acc: 0.8515\n",
      "\n",
      "Epoch 00048: val_loss did not improve from 0.43999\n",
      "Epoch 49/200\n",
      "8000/8000 [==============================] - 52s 6ms/step - loss: 0.0161 - acc: 0.9945 - val_loss: 0.7562 - val_acc: 0.8525\n",
      "\n",
      "Epoch 00049: val_loss did not improve from 0.43999\n",
      "Epoch 50/200\n",
      "8000/8000 [==============================] - 52s 6ms/step - loss: 0.0148 - acc: 0.9950 - val_loss: 0.6778 - val_acc: 0.8525\n",
      "\n",
      "Epoch 00050: val_loss did not improve from 0.43999\n",
      "Epoch 51/200\n",
      "8000/8000 [==============================] - 52s 6ms/step - loss: 0.0183 - acc: 0.9939 - val_loss: 0.6833 - val_acc: 0.8505\n",
      "\n",
      "Epoch 00051: val_loss did not improve from 0.43999\n",
      "Epoch 52/200\n",
      "8000/8000 [==============================] - 52s 7ms/step - loss: 0.0155 - acc: 0.9952 - val_loss: 0.6928 - val_acc: 0.8540\n",
      "\n",
      "Epoch 00052: val_loss did not improve from 0.43999\n",
      "Epoch 53/200\n",
      "8000/8000 [==============================] - 52s 6ms/step - loss: 0.0117 - acc: 0.9965 - val_loss: 0.7183 - val_acc: 0.8510\n",
      "\n",
      "Epoch 00053: val_loss did not improve from 0.43999\n",
      "Epoch 54/200\n",
      "8000/8000 [==============================] - 52s 6ms/step - loss: 0.0108 - acc: 0.9962 - val_loss: 0.7356 - val_acc: 0.8530\n",
      "\n",
      "Epoch 00054: val_loss did not improve from 0.43999\n",
      "Epoch 55/200\n",
      "8000/8000 [==============================] - 52s 6ms/step - loss: 0.0152 - acc: 0.9944 - val_loss: 0.7151 - val_acc: 0.8540\n",
      "\n",
      "Epoch 00055: val_loss did not improve from 0.43999\n",
      "Epoch 56/200\n",
      "8000/8000 [==============================] - 52s 6ms/step - loss: 0.0132 - acc: 0.9960 - val_loss: 0.7168 - val_acc: 0.8555\n",
      "\n",
      "Epoch 00056: val_loss did not improve from 0.43999\n",
      "Epoch 57/200\n",
      "8000/8000 [==============================] - 52s 6ms/step - loss: 0.0141 - acc: 0.9961 - val_loss: 0.7215 - val_acc: 0.8545\n",
      "\n",
      "Epoch 00057: val_loss did not improve from 0.43999\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f3ef041fa90>"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_checkpoint = ModelCheckpoint(\"./Third_net.model\", save_best_only=True, verbose=1)\n",
    "model.fit(X_train, y_train,\n",
    "              batch_size=batch_size,\n",
    "              epochs=nb_epoch,\n",
    "              validation_data=(X_test, y_test),\n",
    "              shuffle=True,\n",
    "              callbacks=[lr_reducer, early_stopper, csv_logger,model_checkpoint])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#model=load_model(\"./resnet_cat_dog.model\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#model=load_model(\"./Net2.model\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#model=load_model(\"./Net3.model\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#model=load_model(\"./Res_50.model\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "del X_train,X_test\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "test_y=pd.read_csv(os.getcwd()+'/test.csv')\n",
    "test=pd.DataFrame()\n",
    "test['label']=test_y['label']\n",
    "test['images']=test_y['images']\n",
    "\n",
    "\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8000\n"
     ]
    }
   ],
   "source": [
    "print(len(test['images']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "32ea8d1d1d3547609e79487de18fe535",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "A Jupyter Widget"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "test[\"data\"] = [np.array(load_img(os.getcwd()+\"/train/{}\".format(idx), target_size=(122,122))) / 255 for idx in tqdm_notebook(test['images'])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "test_in=np.array(test['data'].tolist())\n",
    "test_re=np.array(test['label'].tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 0, 0, 1, 0, 0, 1, 1, 1, 0])"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_re[0:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\n",
    "pre=model.predict(test_in)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1.60368960e-04, 9.99839664e-01],\n",
       "       [9.99997735e-01, 2.28557928e-06],\n",
       "       [1.00000000e+00, 1.07541524e-10],\n",
       "       [6.92855508e-07, 9.99999285e-01],\n",
       "       [6.17872807e-04, 9.99382138e-01],\n",
       "       [1.00000000e+00, 3.84217940e-13],\n",
       "       [4.80419430e-07, 9.99999523e-01],\n",
       "       [1.39408976e-05, 9.99986053e-01],\n",
       "       [7.55863249e-01, 2.44136721e-01],\n",
       "       [3.74202020e-02, 9.62579846e-01]], dtype=float32)"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pre[0:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "pre=np.argmax(pre,axis=1)   \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "test_re=np.array(test_re)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1 0 0 1 1 0 1 1 0 1]\n",
      "[1 0 0 1 0 0 1 1 1 0]\n"
     ]
    }
   ],
   "source": [
    "print(pre[0:10])\n",
    "print(test_re[0:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "14"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "del(test)\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Correct: 6874\n",
      "Wrong: 1126\n",
      "Acc: 0.85925\n"
     ]
    }
   ],
   "source": [
    "correct=0\n",
    "wrong=0\n",
    "for i in range(len(pre)):\n",
    "    if pre[i]==test_re[i]:\n",
    "        correct+=1\n",
    "    else:\n",
    "        wrong+=1\n",
    "print(\"Correct:\",correct)\n",
    "print(\"Wrong:\",wrong)\n",
    "print(\"Acc:\",float(correct/(correct+wrong)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
